# 体系结构#
## 64.综述 ##
### 64.1. NoSQL? ###
Hbase是一种“NoSQL”数据库。“NoSQL”是一个通用术语，代表该数据库不支持SQL数据库作为其主要访问语言。有许多种NoSQL数据库： BerkeleyDB是本地NoSQL数据库的例子，而HBase是分布式数据库。技术上讲，HBase比起数据库，更像一个“数据存储”。因为它缺少很多RDBMS中的特性，如类型列，第二索引，触发器和公安机关查询语言等。

当然，Hbase具有许多特性支持线性和模块化。通过增加托管在有用类服务器上的region server来扩展Hbase集群。例如，如果一个集群从10个RegionServer扩展到20个，它的处理能力和存储容量都翻倍。An RDBMS can scale well, but only up to a point-特别是，单个数据库服务器的规模-最好的的性能要求特殊的硬件和存储设备。Hbase的特性有：

- 强读写一致性：Hbase不是一个最终一致的数据存储。这使它非常适用于高速计数器聚合类的任务。
- 自动分片：HBase表通过区域分布在集群上，随着数据增多，区域会自动分割并重新分布。
- regionserver自动故障转移。
- Hadoop/HDFS整合：HBase天生支持HDFS作为其分布式文件系统。
- MapReduce: 通过使用HBase作为源和汇的MR，Hbase支持大量并行处理。
- java client api:HBase支持一个易于使用的java API的编程访问。
- Thrift/REST API：HBase也支持Thrift 和Rest非java前端。
- Block Cache and Bloom Filters:Hbase支持块缓存和Bloom fliters以实现大批量查询优化。
- Operational Management运营管理: HBase提供建于网页的操作视角以及JMX标准。

### 64.2.何时应该使用HBase？ ###

HBase不适合所有问题。

首先，确保你有足够数据，如果你有许多许多行，Hbase是个不错的选择。如果你只有几千行，或许使用传统RDBMS是个更换的选择，因为你所有的数据可能围绕一个单一（或2个）节点而余下的集群则闲置下来。

第二，确保你不需要RDBMS提供的那些额外功能（如类型列，次要索引，transaction，高级查询语言），一个建立在RDBMS上的应用程序不能通过简单地改变JDBC驱动程序就移植到HBase上。例如，要考虑好从RDBMS移植到HBase是一个完整的重新设计，而不是一个端口。

第三， 确保你有足够多的硬件，即使是HDFS在没有多于5个DataNodes的情况下也无法正常工作，因为默认HDfS块有三个副本，加一个NameNode。

HBase可以在笔记本上很好的运行stand-alone模式，但这只是一个开发配置而已。

### 64.3.HBase与Hadoop/HDFS之间的区别 ###

HDFS是分布式文件系统很适合存储大文件。它的文档声称，无论怎样，它不是一个通用的文件系统,不支持快速个人数据的文件查询。换句话说，HBase是建立在HDFS之上，并提供巨大表格的快速记录查询。这有时会让人产生概念上的困扰。Hbase内部将数据存储在被索引的StoreFiles中，这个文件存在于HDFS中可供高速查询。

## 65. 目录表##
目录表hbase:meta是HBase中的一张表，当使用list命令时可以显示器内容，但和其他表一样就是一张表。

### 65.1. -ROOT- ###
-ROOT-表在Hbase0.96.0中被移除了。

0.96之前-ROOT-表记录了.META表（之前的叫法，现在叫hbae:meta）的位置。-ROOT-结构如下：

***Key***

- .META. region key (.META.,,1)

***Values***



- info:regioninfo  (hbase:meta的序列化HRegionInfo实例)
- info:server(server:持有hbase:meta的RegionServer端口)
- info:serverstartcode(持有hbase:meta的RegionServer进程的开始时间)


### 65.2.hbase:meta ###
 hbase:meta表之前称为.META在系统中记录包含所有区域的一张表。hbase:meta的位置之前可以在-ROOT-表中获取，如今存储在ZooKeeper中。

其结构如下：

***Key***

- 格式的区域键（[table],[region start key],[region id]）

***Values***

- info:regioninfo (这个区域的序列化HRegionInfo实例）
- info:server(server:包含这个区域的RegionServer端口)
- info:serverstartcode(包含这个区域的RegionServer进程开始时间)

当一个表正处于分割进程时，两列将被创建，叫做info:splitA和info:splitB。这两列代表两个子区域。这两列的值也是序列化的HRegionInfo实例。在区域分裂完毕之后，这行将被删除。

### 65.3. 开始序列 ###
首先，在Zookeeper中查到hbase:meta位置，然后，使用server和startcode更新hbase:meta。

## 66.客户端 ##

客户端找出为特定感兴趣范围行服务的RegionSevers.通过查询hbase:meta表。hbase:meta for更多细节。在定位好要求的区域后，客户端与服务那个region的RegionServer进行联系，而不是主节点，然后发送读写请求。这个信息被缓存在客户端，以便后续请求不需要进行查找流程。区域应该被重新分配或者通过主节点负载均衡或因为某个RegionServer挂掉，客户端将查询目录表来确定用户区的新位置。

See Runtime Impact for more information about the impact of the Master on HBase Client communication.

Administrative functions are done via an instance of Admin

### 66.1.集群连接 ###
The API changed in HBase 1.0. For connection configuration information, see Client configuration and dependencies connecting to an HBase cluster.

#### 66.1.1HBase 1.0.0的API ####
It’s been cleaned up and users are returned Interfaces to work against rather than particular types.在HBase1.0中，从ConnectionFactory获得一个连接对象，然后按需从中获得它的实例表、管理员和RegionLocator。当完成后，关闭获取的实例。最终，确保在退出前清理你的Connection实例。连接时重量级对象，但线程安全，所以可以为应用创建一个，并保持这个实例。Table,Admin以及RegionLocator实例是轻量级的。使用时创建，用完后尽快释放。

#### 66.1.2. HBase1.0.0之前的API ####
HTable实例是1.0版之前与HBase集群交互的方式。Table实例不是线程安全的。在任何给定时间，表实例只能被一个线程使用。当创建表实例时，建议使用同样的HBaseConfiguration实例。这样可以保证共享RegionServers的ZooKeeper和socket实例，这通常是你想要的。例如，推荐如下：
	
	HBaseConfiguration conf = HBaseConfiguration.create();
	HTable table1 = new HTable(conf, "myTable");
	HTable table2 = new HTable(conf, "myTable");

反对这样：
	
	HBaseConfiguration conf1 = HBaseConfiguration.create();
	HTable table1 = new HTable(conf1, "myTable");
	HBaseConfiguration conf2 = HBaseConfiguration.create();
	HTable table2 = new HTable(conf2, "myTable");

For more information about how connections are handled in the HBase client, see ConnectionFactory.

**连接池**
对于需要high-end多线程访问的应用程序（web-servers或application-servers在一个JVM中提供多个应用程序线程），可以先创建一个连接，像下面例子这样。

***Example 37. Pre-Creating a Connection***

	// Create a connection to the cluster.
	Configuration conf = HBaseConfiguration.create();
	try (Connection connection = ConnectionFactory.createConnection(conf)) {
  	  try (Table table = connection.getTable(TableName.valueOf(tablename)) {
   		 // use table as needed, the table returned is lightweight
  	  }
	}
	
构建HTableInterfaces实现是非常轻量级，并且资源可控的。

### 66.2.  WriteBuffer and Batch Methods###
在HBase1.0之后，HTable被反对而支持Table.Table不使用autoflush。要做缓冲写入，使用BufferedMutator类。

在Table或HTable被丢弃之前，调用close()或flushCommits(), 这样Put不会丢失。

For additional information on write durability, review the ACID semantics page.

For fine-grained control of batching of Puts or Deletes, see the batch methods on Table.

### 66.3 外部ClientExternal客户端 ###

Information on non-Java clients and custom protocols is covered in Apache HBase External APIs。

## 67. 客户请求过滤器 ##
Get和Scan实例可以可选地配置应用在RegionServer上的过滤器。

过滤器可能很烦人因为会有许多不同种类，理解组的过滤功能是最好的了解他们的方法。

### 67.1. Structural###
Structural过滤包含其他过滤器。

#### 67.1.1.过滤表 ####
过滤表代表过滤表之间FilterList.Operator.MUST_PASS_ALL或FilterList.Operator.MUST_PASS_ONE关系的过滤表。下面是or过滤的例子

	FilterList list = new FilterList(FilterList.Operator.MUST_PASS_ONE);
	SingleColumnValueFilter filter1 = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my value")
  	  );
	list.add(filter1);
	SingleColumnValueFilter filter2 = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my other value")
  	 );
	list.add(filter2);
	scan.setFilter(list);

### 67.2 列值 ###
### 67.2.1.单列值过滤 ###
SingleColumnValueFilter可以被用来测试列值相等（CompareOp.EQUAL）、不相等（CompareOp.NOT_EQUAL)）或范围（e.g., CompareOp.GREATER）。下面是一个测试列值等于“my value”的例子。

	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my value")
  	  );
	scan.setFilter(filter);

### 67.3.列值比较 ###
有几个比较类的过滤包，是值得介绍的。这些过滤器与其他过滤器一起使用，如上面介绍的 SingleColumnValueFilter.

#### 67.3.1.正则表达式Comparator####
RegexStringComparator支持值比较的常规表达。

	RegexStringComparator comp = new RegexStringComparator("my.");   // any value that starts with 'my'
	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  comp
  	  );
	scan.setFilter(filter);

#### 67.3.2. 子串比较器 ####
子串比较器用于决定一个给定的子串是否存于一个值中。这种比较是大小写敏感的。

	SubstringComparator comp = new SubstringComparator("y val");   // looking for 'my value'
	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  comp
  	  );
	scan.setFilter(filter);

#### 67.3.3.BinaryPrefixComparator ####

#### 67.3.4. BinaryComparator ####

### 67.4. 键值元数据###
HBase内部以键值对的方式存储数据，  KeyValue Metadata Filters evaluate the existence of keys (i.e., ColumnFamily:Column qualifiers) for a row, as opposed to values the previous section.

#### 67.4.1. familyFilter ###
FamilyFilter 可以用在过滤 ColumnFamily上.Scan中选择ColumnFamliy比用过滤，通常是一个更好的主意。

#### 67.4.2. QualifierFilter ####
QualifierFilter可用来列名基础上的过滤。

#### 67.4.3. ColumnPrefixFilter####
ColumnPrefixFilter可用于基于部分列名的过滤。

ColumnPrefixFilter寻找每个相关列族和每列中第一个匹配的前缀。可以用来在很宽的行中高效的获取列的子集。

注意：相同的列限定符可在不同的列族中使用。这个过滤器返回所有匹配的列。

例子：在行和族中找到以"abc"开头的列

	HTableInterface t = ...;
	byte[] row = ...;
	byte[] family = ...;
	byte[] prefix = Bytes.toBytes("abc");
	Scan scan = new Scan(row, row); // (optional) limit to one row
	scan.addFamily(family); // (optional) limit to one family
	Filter f = new ColumnPrefixFilter(prefix);
	scan.setFilter(f);
	scan.setBatch(10); // set this if there could be many columns returned
	ResultScanner rs = t.getScanner(scan);
	for (Result r = rs.next(); r != null; r = rs.next()) {
  	  for (KeyValue kv : r.raw()) {
    	// each kv represents a column
  	  }
	}
	rs.close();

#### 67.4.4. MultipleColumnPrefixFilter ####
