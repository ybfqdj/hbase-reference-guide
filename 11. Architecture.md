# 体系结构#
## 64.综述 ##
### 64.1. NoSQL? ###
Hbase是一种“NoSQL”数据库。“NoSQL”是一个通用术语，代表该数据库不支持SQL数据库作为其主要访问语言。有许多种NoSQL数据库： BerkeleyDB是本地NoSQL数据库的例子，而HBase是分布式数据库。技术上讲，HBase比起数据库，更像一个“数据存储”。因为它缺少很多RDBMS中的特性，如类型列，第二索引，触发器和公安机关查询语言等。

当然，Hbase具有许多特性支持线性和模块化。通过增加托管在有用类服务器上的region server来扩展Hbase集群。例如，如果一个集群从10个RegionServer扩展到20个，它的处理能力和存储容量都翻倍。An RDBMS can scale well, but only up to a point-特别是，单个数据库服务器的规模-最好的的性能要求特殊的硬件和存储设备。Hbase的特性有：

- 强读写一致性：Hbase不是一个最终一致的数据存储。这使它非常适用于高速计数器聚合类的任务。
- 自动分片：HBase表通过区域分布在集群上，随着数据增多，区域会自动分割并重新分布。
- regionserver自动故障转移。
- Hadoop/HDFS整合：HBase天生支持HDFS作为其分布式文件系统。
- MapReduce: 通过使用HBase作为源和汇的MR，Hbase支持大量并行处理。
- java client api:HBase支持一个易于使用的java API的编程访问。
- Thrift/REST API：HBase也支持Thrift 和Rest非java前端。
- Block Cache and Bloom Filters:Hbase支持块缓存和Bloom fliters以实现大批量查询优化。
- Operational Management运营管理: HBase提供建于网页的操作视角以及JMX标准。

### 64.2.何时应该使用HBase？ ###

HBase不适合所有问题。

首先，确保你有足够数据，如果你有许多许多行，Hbase是个不错的选择。如果你只有几千行，或许使用传统RDBMS是个更换的选择，因为你所有的数据可能围绕一个单一（或2个）节点而余下的集群则闲置下来。

第二，确保你不需要RDBMS提供的那些额外功能（如类型列，次要索引，transaction，高级查询语言），一个建立在RDBMS上的应用程序不能通过简单地改变JDBC驱动程序就移植到HBase上。例如，要考虑好从RDBMS移植到HBase是一个完整的重新设计，而不是一个端口。

第三， 确保你有足够多的硬件，即使是HDFS在没有多于5个DataNodes的情况下也无法正常工作，因为默认HDfS块有三个副本，加一个NameNode。

HBase可以在笔记本上很好的运行stand-alone模式，但这只是一个开发配置而已。

### 64.3.HBase与Hadoop/HDFS之间的区别 ###

HDFS是分布式文件系统很适合存储大文件。它的文档声称，无论怎样，它不是一个通用的文件系统,不支持快速个人数据的文件查询。换句话说，HBase是建立在HDFS之上，并提供巨大表格的快速记录查询。这有时会让人产生概念上的困扰。Hbase内部将数据存储在被索引的StoreFiles中，这个文件存在于HDFS中可供高速查询。

## 65. 目录表##
目录表hbase:meta是HBase中的一张表，当使用list命令时可以显示器内容，但和其他表一样就是一张表。

### 65.1. -ROOT- ###
-ROOT-表在Hbase0.96.0中被移除了。

0.96之前-ROOT-表记录了.META表（之前的叫法，现在叫hbae:meta）的位置。-ROOT-结构如下：

***Key***

- .META. region key (.META.,,1)

***Values***



- info:regioninfo  (hbase:meta的序列化HRegionInfo实例)
- info:server(server:持有hbase:meta的RegionServer端口)
- info:serverstartcode(持有hbase:meta的RegionServer进程的开始时间)


### 65.2.hbase:meta ###
 hbase:meta表之前称为.META在系统中记录包含所有区域的一张表。hbase:meta的位置之前可以在-ROOT-表中获取，如今存储在ZooKeeper中。

其结构如下：

***Key***

- 格式的区域键（[table],[region start key],[region id]）

***Values***

- info:regioninfo (这个区域的序列化HRegionInfo实例）
- info:server(server:包含这个区域的RegionServer端口)
- info:serverstartcode(包含这个区域的RegionServer进程开始时间)

当一个表正处于分割进程时，两列将被创建，叫做info:splitA和info:splitB。这两列代表两个子区域。这两列的值也是序列化的HRegionInfo实例。在区域分裂完毕之后，这行将被删除。

### 65.3. 开始序列 ###
首先，在Zookeeper中查到hbase:meta位置，然后，使用server和startcode更新hbase:meta。

## 66.客户端 ##

客户端找出为特定感兴趣范围行服务的RegionSevers.通过查询hbase:meta表。hbase:meta for更多细节。在定位好要求的区域后，客户端与服务那个region的RegionServer进行联系，而不是主节点，然后发送读写请求。这个信息被缓存在客户端，以便后续请求不需要进行查找流程。区域应该被重新分配或者通过主节点负载均衡或因为某个RegionServer挂掉，客户端将查询目录表来确定用户区的新位置。

See Runtime Impact for more information about the impact of the Master on HBase Client communication.

Administrative functions are done via an instance of Admin

### 66.1.集群连接 ###
The API changed in HBase 1.0. For connection configuration information, see Client configuration and dependencies connecting to an HBase cluster.

#### 66.1.1HBase 1.0.0的API ####
It’s been cleaned up and users are returned Interfaces to work against rather than particular types.在HBase1.0中，从ConnectionFactory获得一个连接对象，然后按需从中获得它的实例表、管理员和RegionLocator。当完成后，关闭获取的实例。最终，确保在退出前清理你的Connection实例。连接时重量级对象，但线程安全，所以可以为应用创建一个，并保持这个实例。Table,Admin以及RegionLocator实例是轻量级的。使用时创建，用完后尽快释放。

#### 66.1.2. HBase1.0.0之前的API ####
HTable实例是1.0版之前与HBase集群交互的方式。Table实例不是线程安全的。在任何给定时间，表实例只能被一个线程使用。当创建表实例时，建议使用同样的HBaseConfiguration实例。这样可以保证共享RegionServers的ZooKeeper和socket实例，这通常是你想要的。例如，推荐如下：
	
	HBaseConfiguration conf = HBaseConfiguration.create();
	HTable table1 = new HTable(conf, "myTable");
	HTable table2 = new HTable(conf, "myTable");

反对这样：
	
	HBaseConfiguration conf1 = HBaseConfiguration.create();
	HTable table1 = new HTable(conf1, "myTable");
	HBaseConfiguration conf2 = HBaseConfiguration.create();
	HTable table2 = new HTable(conf2, "myTable");

For more information about how connections are handled in the HBase client, see ConnectionFactory.

**连接池**
对于需要high-end多线程访问的应用程序（web-servers或application-servers在一个JVM中提供多个应用程序线程），可以先创建一个连接，像下面例子这样。

***Example 37. Pre-Creating a Connection***

	// Create a connection to the cluster.
	Configuration conf = HBaseConfiguration.create();
	try (Connection connection = ConnectionFactory.createConnection(conf)) {
  	  try (Table table = connection.getTable(TableName.valueOf(tablename)) {
   		 // use table as needed, the table returned is lightweight
  	  }
	}
	
构建HTableInterfaces实现是非常轻量级，并且资源可控的。

### 66.2.  WriteBuffer and Batch Methods###
在HBase1.0之后，HTable被反对而支持Table.Table不使用autoflush。要做缓冲写入，使用BufferedMutator类。

在Table或HTable被丢弃之前，调用close()或flushCommits(), 这样Put不会丢失。

For additional information on write durability, review the ACID semantics page.

For fine-grained control of batching of Puts or Deletes, see the batch methods on Table.

### 66.3 外部ClientExternal客户端 ###

Information on non-Java clients and custom protocols is covered in Apache HBase External APIs。

## 67. 客户请求过滤器 ##
Get和Scan实例可以可选地配置应用在RegionServer上的过滤器。

过滤器可能很烦人因为会有许多不同种类，理解组的过滤功能是最好的了解他们的方法。

### 67.1. Structural###
Structural过滤包含其他过滤器。

#### 67.1.1.过滤表 ####
过滤表代表过滤表之间FilterList.Operator.MUST_PASS_ALL或FilterList.Operator.MUST_PASS_ONE关系的过滤表。下面是or过滤的例子

	FilterList list = new FilterList(FilterList.Operator.MUST_PASS_ONE);
	SingleColumnValueFilter filter1 = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my value")
  	  );
	list.add(filter1);
	SingleColumnValueFilter filter2 = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my other value")
  	 );
	list.add(filter2);
	scan.setFilter(list);

### 67.2 列值 ###
### 67.2.1.单列值过滤 ###
SingleColumnValueFilter可以被用来测试列值相等（CompareOp.EQUAL）、不相等（CompareOp.NOT_EQUAL)）或范围（e.g., CompareOp.GREATER）。下面是一个测试列值等于“my value”的例子。

	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  Bytes.toBytes("my value")
  	  );
	scan.setFilter(filter);

### 67.3.列值比较 ###
有几个比较类的过滤包，是值得介绍的。这些过滤器与其他过滤器一起使用，如上面介绍的 SingleColumnValueFilter.

#### 67.3.1.正则表达式Comparator####
RegexStringComparator支持值比较的常规表达。

	RegexStringComparator comp = new RegexStringComparator("my.");   // any value that starts with 'my'
	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  comp
  	  );
	scan.setFilter(filter);

#### 67.3.2. 子串比较器 ####
子串比较器用于决定一个给定的子串是否存于一个值中。这种比较是大小写敏感的。

	SubstringComparator comp = new SubstringComparator("y val");   // looking for 'my value'
	SingleColumnValueFilter filter = new SingleColumnValueFilter(
  	  cf,
  	  column,
  	  CompareOp.EQUAL,
  	  comp
  	  );
	scan.setFilter(filter);

#### 67.3.3.BinaryPrefixComparator ####

#### 67.3.4. BinaryComparator ####

### 67.4. 键值元数据###
HBase内部以键值对的方式存储数据，  KeyValue Metadata Filters evaluate the existence of keys (i.e., ColumnFamily:Column qualifiers) for a row, as opposed to values the previous section.

#### 67.4.1. familyFilter ###
FamilyFilter 可以用在过滤 ColumnFamily上.Scan中选择ColumnFamliy比用过滤，通常是一个更好的主意。

#### 67.4.2. QualifierFilter ####
QualifierFilter可用来列名基础上的过滤。

#### 67.4.3. ColumnPrefixFilter####
ColumnPrefixFilter可用于基于部分列名的过滤。

ColumnPrefixFilter寻找每个相关列族和每列中第一个匹配的前缀。可以用来在很宽的行中高效的获取列的子集。

注意：相同的列限定符可在不同的列族中使用。这个过滤器返回所有匹配的列。

例子：在行和族中找到以"abc"开头的列

	HTableInterface t = ...;
	byte[] row = ...;
	byte[] family = ...;
	byte[] prefix = Bytes.toBytes("abc");
	Scan scan = new Scan(row, row); // (optional) limit to one row
	scan.addFamily(family); // (optional) limit to one family
	Filter f = new ColumnPrefixFilter(prefix);
	scan.setFilter(f);
	scan.setBatch(10); // set this if there could be many columns returned
	ResultScanner rs = t.getScanner(scan);
	for (Result r = rs.next(); r != null; r = rs.next()) {
  	  for (KeyValue kv : r.raw()) {
    	// each kv represents a column
  	  }
	}
	rs.close();

#### 67.4.4. MultipleColumnPrefixFilter ####
MultipleColumnPrefixFilter和列前缀过滤类似，只不过允许指定多个前缀。Like ColumnPrefixFilter, MultipleColumnPrefixFilter 有效地从列开头查找匹配的前缀中 and also seeks past ranges of columns between prefixes.它可以有效地从广泛的行获得不连续的列。

Example: Find all columns in a row and family that start with "abc" or "xyz"

	HTableInterface t = ...;
	byte[] row = ...;
	byte[] family = ...;
	byte[][] prefixes = new byte[][] {Bytes.toBytes("abc"), Bytes.toBytes("xyz")};
	Scan scan = new Scan(row, row); // (optional) limit to one row
	scan.addFamily(family); // (optional) limit to one family
	Filter f = new MultipleColumnPrefixFilter(prefixes);
	scan.setFilter(f);
	scan.setBatch(10); // set this if there could be many columns returned
	ResultScanner rs = t.getScanner(scan);
	for (Result r = rs.next(); r != null; r = rs.next()) {
  	  for (KeyValue kv : r.raw()) {
    	// each kv represents a column
  	 }
	}
	rs.close();

#### 67.4.5列范围过滤器 ####
列范围过滤器允许有效地行内扫描。

ColumnRangeFilter 从相关列族的开头开始查找第一个匹配。可以很高效地从很宽的一列中获得一列的一部分。如，在一行中你有一百万列，但你只想查看列bbbb-bbbd。

注意：在不同列族中可能使用相同列名。这个过滤器返回所有匹配的列。

Example: Find all columns in a row and family between "bbbb" (inclusive) and "bbdd" (inclusive)

	HTableInterface t = ...;
	byte[] row = ...;
	byte[] family = ...;
	byte[] startColumn = Bytes.toBytes("bbbb");
	byte[] endColumn = Bytes.toBytes("bbdd");
	Scan scan = new Scan(row, row); // (optional) limit to one row
	scan.addFamily(family); // (optional) limit to one family
	Filter f = new ColumnRangeFilter(startColumn, true, endColumn, true);
	scan.setFilter(f);
	scan.setBatch(10); // set this if there could be many columns returned
	ResultScanner rs = t.getScanner(scan);
	for (Result r = rs.next(); r != null; r = rs.next()) {
  		for (KeyValue kv : r.raw()) {
    	// each kv represents a column
  	   }
	}
	rs.close();

### 67.5.行键 ###
#### 67.5.1.行过滤器 ####
为了选择行，在Scan中使用startRow/stopRow方法是个好主意，当然也可以使用RowFilter。

### 67.6 Utility ###
#### 67.6.1  FirstKeyOnlyFilter####
This is primarily used for rowcount jobs.

## 68. Master ##
hmaster是主服务器的实现。Master服务器负责检测集群中所有的RegionServer实例， 是所有元数据改变的接口。在分布式集群中，Master一般在NameNode上运行。

### 68.1.启动行为 ###
如果在多Master环境中运行，所有Master竞争运行集群。如果主Master失去租约（或Master关闭），那么剩下的Master争相成为active Master.

### 68.2.运行时影响 ###
一个常见的分布式问题涉及到当Master挂掉，Hbase集群将发生什么。因为HBase客户端直接和RegionServer通信，集群将仍然处于“steady state”的功能状态。另外，每个目录表，hbase:meta作为Hbase 表存在，而不是待在Master中。当然，Master控制一些重要的功能，如regionserver的故障转移和完成区域分割。所以，集群仍可以在没有Master情况下运行一段时间，Master应尽可能快得重启。

### 68.3.接口 ###
HMasterinterface开放的方法主要是面向元数据的方法：

- Table(createTable, modifyTable,removeTalbe,enable, disable)
- ColumnFamily(addColumn, modifyColumn,removeColumn)
- Region(move, assign, unassign) 例如当引用Admin方法disableTable时，它是由Master服务器服务的。

### 68.4.进程 ###

Master提供一些背景线程：

#### 68.4.1.负载均衡 ####
周期性地，当没有区域在转换时，负载均衡器将运行起来，将区域移动来平衡集群负载。 See Balancer for configuring this property.

See Region-RegionServer Assignment for more information on region assignment.

#### 68.4.2. CatalogJanitor ####
周期性地检查并清理hbase:meta表。

## 69. 区域服务器 ##
HRegionServer是RegionServer的实现。它负责服务和管理区域。在分布式集群中，区域服务器运行在DataNode上。

### 69.1.接口 ###
HRegionRegionInterface开放的方法包括面向数据的和区域维护的方法：

- Data(get, put, delete, next, etc.)
- Region(splitRegion, compactRegion, 等)当Admin的majorCompact方法对某个表被调用时，客户端是遍历所有区域查找指定的表，并直接向每个区域请求主紧缩。

### 69.2.进程 ###
区域服务器运行多种多样的背景线程：

#### 69.2.1 主分割线程 ####
Checks for splits and handle minor compactions.

#### 69.2.2. MajorCompactionChecker ####
Checks for major compactions.

#### 69.2.3. MemStoreFlusher ####
周期性刷新内存将MemStore中内容写入StoreFiles.

#### 69.2.4. LogRoller ####
周期性检查RegionServer的WAL

### 69.3.协处理器 ###
协处理器是在0.92.中别加入的。There is a thorough Blog Overview of CoProcessors posted. Documentation will eventually move to this reference guide, but the blog is the most current information available at this time.

### 69.4.块缓存 ###
HBase提供两种不同的块缓存实现：默认的堆上 LruBlockCache和BucketCache(非堆内存)。这小节将讨论每种方法的优缺点，怎样选择合适的方法，以及每种选择的配置方法。

#### 69.4.1.缓存选择 ####
LruBlockCache是最初的方法，全部在Java堆中。BucketCache主要用来在非堆内存中保存块缓存，尽管BucketCache也能在堆内存上保存数据并从文件支持的缓存中服务。

当从BucketCache中取永远比本地堆上的LruBlockCache慢。当然，延迟往往是不稳定的时间， 因为当使用BucketCache时，会有更少的垃圾收集，因它是管理blockcache分配，不是GC。如果BucketCache使用非堆内存模式，这种内存完全不适用GC管理。这是为什么你使用BucketCache, 为了减轻GCS和堆碎片延迟不稳定，See Nick Dimiduk’s BlockCache 101 for comparisons running on-heap vs off-heap tests. Also see Comparing BlockCache Deploys which finds that if your dataset fits inside your LruBlockCache deploy, use it otherwise if you are experiencing cache churn (or you want your cache to exist beyond the vagaries of java GC), use BucketCache.

当启用BucketCache,你使用一个二级缓存系统，第一层缓存由LruBlockCache实例实现，第二层的非堆内存是由BucketCache实现。这两层的管理和政策决定块之间移动是怎样通过CombinedBlockCache实现的。L2 BucketCache中保存了所有DATA块，而元数据-INDEX和BLOOM块在L1 LruBlockCache的堆内存中。

#### 69.4.2.一般缓存设置 ####
除了缓存实现本身之外，您也可以设置一些一般性的配置选项来控制缓存如何执行。在设置任何这些选项后，重新启动或轮流重新启动您的集群使配置生效。发生错误和未知行为请查看日志。

#### 69.4.3 LruBlockCache Design####
LruBlockCache是一个LRU缓存，包含3个层面的块优先级，允许列族内存性能和内存扫描：

- 单一接入优先级：第一次块被从HDFS中加载出来，它通常具有这类优先级，属于evitions阶段要考虑的第一组。优点是扫描块比使用越来越多的使用块更容易被evicted。
- 多接入优先级：如果前面优先级组的块被再次访问，则将升级到整个优先级。因此，它是evictions时第二组要被考虑的。
- 内存接入优先级：如果某个块的族被配置为“内存”，它将成为这类优先级不管本次访问的次数。目录表被设置为此类。这是evictions时最后要考虑的。

要将某个列族标记为in-memory， 调用
	
	HColumnDescriptor.setInMemory(true);

如果从java创建某个表，或当在shell中创建或更改表时设置**IN_MEMORY=>true** ： 如

	hbase(main):003:0> create  't', {NAME => 'f', IN_MEMORY => 'true'}

#### 69.4.4 LruBlockCache 使用 ####
块缓存对用户表时默认打开的，这意味着任何读操作将加载LRU缓存。这可能对大部分用例都是好的，但进一步调优通常是需要的为了获得更好的性能。working set size*(WSS)是一个重要的概念，它是指计算某个问题答案所需要的内存量。对网页来说，这将是完成短时间内查询所需要的数据。

	Hbase缓存需要多少内存是这样计算的：

	number of region servers * heap size * hfile.block.cache.size * 0.99

块缓存的默认值是0.25，这代表可获得堆的25%。最后的值（99%）是在eviction被开始后LRU缓存中默认的可接受负载因子。它被包含进这个等式的原因是声称使用了百分百可获得内存是不现实的，因为这将使进程在它载入新块时，阻塞旧块。下面是一些例子：

- 1个区域服务器，设置1GB的堆内存大小，默认块缓存大小将有可获得块缓存的253MB。
- 20个区域服务器， 设置8GB堆缓存，默认块缓存将有39.6GB
- 100个区域服务器，设置24gb堆缓存，默认缓存将有1.16TB。

数据并不仅仅停留在块缓存上，这里有些其他事情是你要考虑的：

**目录表**
-ROOT-(0.96之前)和hbase:meta表要强制存于块缓存中并要有内存优先级，则会表示他们很难被驱逐。前者从未占用超过几百个字节，而后者能占一些MB(与区域数有关)。

**HFiles索引**
HFiles是Hbase用来在HDFS中存储数据的文件格式。它包含多层索引，允许Hbase查询数据而不用读取整个文件。索引大小是一个块大小因子（默认64K），即所存储的键和数据数量。对大数据的设置，每个区域服务设置成1GB并不常见，尽管并不是所有的都会在缓存中，因为LRU将驱逐不使用的索引。

**Keys**
存储下来的值仅仅是图像的一半，因为每个值是和它键(row key, family qulifier, 以及时间戳)一起存储的。

**Bloom过滤器**
就像HFile索引一样，这些数据结构存储在LRU中。

当前，建议的测量HFiles索引和Bloom过滤器大小的方法是在区域服务器的Web UI中查看，检验相关指标。对keys来说，采样可以使用HFile命令行工具并寻找平均键尺寸指标。从0.98.3之后，可以在BlockCache stats上查看相关细节，在UI中的一个特殊块缓存中度量。

当WSS不适合内存时，通常不使用块缓存。这个例子通常发生在当所有区域服务器块缓存有40GB的可用，而需要处理1TB数据。其中一个原因是，由驱逐产生的改变将导致更多不必要的垃圾收集。这里有两个用例：

- 完全随机读模式：这个例子是你不会在很短时间内访问同一行两次，这样访问一个块缓存的机会接近为零。在这样表中设置块缓存是浪费内存和CPU周期，同样会产生更多的垃圾需要JVM去收集。
- 映射一张表：在一个典型的MR job中使用一张表作为输入，每行将仅被读取一次，所以这里没有必要将他们放入块缓存中。Scan对象有将这个设置为off的选项，通过setCaching方法（设为false）。如果你需要快速的随机读访问，你可以仍将块缓存打开。例子将计算服务实时交通表的行数，缓存表中每个块将产生大量变换，将必定会驱逐当前正在使用的数据。

***仅缓存元数据块***

当我们仅缓存META块时是很有趣的步骤，每次访问都要读取DATA块。如果DATA块放入fscache， 这种可替代方法当对大数据集进行完全随机访问时产生意义。启用这中设置，更改表并将每个列族设置BLOCKCACHE ⇒ 'false'，仅将这个列族的块缓存关闭，永远不能禁用META块的缓存


#### 69.4.5.  Off-heap Block Cache####
**怎样打开BucketCache**
BucketCache的通常部署是通过管理类，设置两个缓存层：一个由LruBlockCache实现的L1堆上缓存；第二个由BucketCache实现的L2缓存。默认管理类是[CombinedBlockCache](http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/io/hfile/CombinedBlockCache.html)。这里链接介绍了CombinedBlockCache实现的缓存策略。简而言之，通过保存元块工作，即在L1堆上LruBlockCache中保存INDEX和BLOOM,L2 BucketCache层中保存DATA块。从1.0版后可以修改这个行为，并要求列族中L1堆内存中即保存meta又保存DATA，通过HColumnDescriptor.setCacheDataInL1(true)设置cacheDataInL1，或在shell中创建并修改列族设置 CACHE_DATA_IN_L1 为真，如：

	hbase(main):003:0> create 't', {NAME => 't', CONFIGURATION => {CACHE_DATA_IN_L1 => 'true'}}

BucketCache块缓存可以部署在堆上，堆下或基于文件。通过hbase.bucketcache.ioengine设置。要设置为heap将把BucketCache部署在分配的Java堆内。设置其为offheap将BucketCache部署在堆外，设置为file:PATH_TO_FILE将使BucketCache使用文件缓存（特别是有类似SSD快速I/O时有用）

绕过CombinedBlockCache策略部署一个L1+L2设置是可能的，让BucketCache工作为严格的L2缓存到L1 LruBlockCache。要实现这个设置，将CacheConfig.BUCKET_CACHE_COMBINED_KEY设为false。这种模式下，来自L1的驱逐，块移至L2。当块被缓存时，首先在L1中缓存。当要查找缓存块时，首先在L1中查找，如果没有找到，再去L2中查找。我们叫这种部署方式：***Raw L1+l2***。


其他BucketCache包括：指定一个用来重启的持续缓存。在写入缓存时用多少线程等。

***BucketCache Example配置***

这个例子提供了一种4GB堆外BucketCache和1GB堆上缓存的配置。

配置在RegionServer上执行。

设置hbase.bucketcache.ioengine 和hbase.bucketcache.size大于零，以启动CombinedBlockCache。我们假定RegionServer设置并运行5G堆内存。如：HBASE_HEAPSIZE=5g

1\. 首先，编辑RegionServer的hbase-env.sh并设置HBASE_OFFHEAPSIZE比想要的堆外内存大一点的值，本例中4G（表示为4G）。设置其为5G。将有4G给堆外缓存和1G其他堆外内存应用（除了BlockCache外会有其他功能使用堆外内存，如RegionServer中的DFSClient）

	HBASE_OFFHEAPSIZE=5G

2\. 下一步，在RegionServer的hbase-site.xml中增加如下配置：

	<property>
  	 <name>hbase.bucketcache.ioengine</name>
  	 <value>offheap</value>
	</property>
	<property>
  	 <name>hfile.block.cache.size</name>
  	 <value>0.2</value>
	</property>
	<property>
   	 <name>hbase.bucketcache.size</name>
  	 <value>4196</value>
	</property>

3\. 重启或rolling restart集群，如果有问题查看log

上面的例子中，我们将BucketCache设为4G，配置堆上LruBlockCache有20%的RegionServer堆大小（0.2*5G=1G）。换言之，配置L1 LruBlockCache像正常一样（就像没有L2缓存存在）

[HBASE-10641](https://issues.apache.org/jira/browse/HBASE-10641) 介绍了给BucketCache的通道配置多个大小的能力，在Hbase0.98之后。要配置多个bucket大小， 配置hfile.block.cache.sizes这个新属性，（替换hfile.block.cache.size），用逗号分隔块大小表，从小到大排序，没有空格。这样的目的是根据数据访问的模式优化bucket大小。下面的例子是配置bucket大小从4096-8192.

	<property>
  	 <name>hfile.block.cache.sizes</name>
  	 <value>4096,8192</value>
	</property>

#### 69.4.6 Compressed BlockCache 压缩的块缓存####
[HBASE-11331 ](https://issues.apache.org/jira/browse/HBASE-11331)介绍了懒惰的BlockCache decompression,比压缩的块缓存要更简单。当压缩块缓存被启用时，数据和编码数据块会以它们的磁盘格式缓存在BlockCache上，而不是在缓存前被解压和解码。

对一个RegionServer 如其比放入缓存，存更多数据，打开这项功能使用SNAPPY压缩，可以增加50%吞吐和改善30%平均延迟，增加垃圾收集80%和增加整体CPU负载2%。See HBASE-11331 for more details about how performance was measured and achieved.如对缓存大小和存储数据大小正合适，或工作负载对于额外的CPU和垃圾收集比较敏感，你将收到很少的好处。

该功能默认关闭，要启用设置所有RegionServer上的hbase-site.xml中的hbase.block.data.cachecompressed为真。

### 69.5. ###
当写请求被RegionServer处理时，它们聚集在称为memstore内存存储系统。一旦memstore满了，其内容被写入磁盘作为额外的存储文件。这种行为称为memstore flush。随着存储文件累计，RegionServer将压缩它们成更少但更大的文件。当每次flush或压缩完成，在区域中存储的数据量就改变了。RegionServer参考看区域分割策略来判断是否区域增长到足够大或根据指定的策略应该被分割。按照策略建议，区域分割请求将进行排队。

逻辑上，分割区域是很简单的一件事。我们在区域键空间中找到一个合适的点来将区域分半，然后将区域数据分到两个区域中。然而这个步骤并不简单。当分割发生时，新创建的子区域并不立刻重写数据到新的文件。而是，创建类似符号链接的小文件，叫做Reference files，这个文件根据分割点指向父文件的顶部或底部。reference files可以像常规文件一样使用，但仅有一般记录被考虑。如果没有对父区域的不可变数据文件的引用，该区域只能被拆分。引用文件随着紧缩逐渐被清除，这样区域将停止引用其父文件，并将进一步被分割。

尽管分割区域是RegionServer的本地决定，分割进程本身必须遵循许多的因素。RegionServer要在split前后通知Master，更新.META.表这样客户端可以发现新的子区域， 并重新安排HDFS中目录结构和数据文件。分割是一个多任务进程。如果在错误状态下启用回滚，RegionServer将在内存日志中保存执行状态。RegionServer执行分割的步骤见RegionServer Split Process。每一步都使用步骤号作为标签。RegionServer和Master的行为使用红线，而客户端使用绿线。
![Figure 1. RegionServer Split Process](http://hbase.apache.org/images/region_split_process.png)

1\.RegionServer决定在本地分割区域，并准备分割。**THE SPLIT TRANSACTION IS STARTED.**第一步，RegionServer获取一个共享读锁在表格上，防止分割中表格被修改。然后在zookeeper的/hbase/region-in-transition/region-name下创建一个znode,并设置其状态为SPLITTING

2\.Master得知这个znode，因为它有个父region-in-transition znode监视器。

3\.RegionServer在HDFS中的父目录region中创建名叫.splits的子目录。

4\.RegionServer关闭父区域并在其本地数据结构中将父区域标记为下线。**THE SPLITTING REGION IS NOW OFFLINE.**这时来到父区域的客户端请求会抛出NotServingRegionException。客户端会重试一些回避。关闭区域被冲洗。

5\.RegionServer在.splits下为子区域A和B创建区域目录，并创建必要的数据结构。然后分割存储文件，在这个意义上，它在父区域为每个存储文件创建两个参考文件。这两个参考文件将指向父区域文件。

6\. RegionServer在HDFS中创建实际的区域目录，并为每个子区域移动参考文件。

7\. RegionServer向.META.表发送一个Put请求，在.META.中设置父区域离线并加入子区域信息。这时，对子区域来说，它们并不是独立的目录。客户端可以看到父区域分裂，如果这时扫描.META.，但并不知道子区域存在，直到它们在.META.中出现。如果Put成功，父将有效地分割。如果在RPC成功之前RegionServer失败，Master和下一个Region Server将清理分割的不正确状态。在.META.更新后了，区域分割将滚动向前。
