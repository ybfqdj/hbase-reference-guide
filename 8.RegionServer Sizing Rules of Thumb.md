#RegionServer Sizing Rules of Thumb
ars Hofhansl wrote a great blog post about RegionServer memory sizing. 结果是你可能需要比你认为的更多的内存。它受到region size、memstoresize、Hdfs replication factor，以及其他要检查的事项的影响。

>  Personally I would place the maximum disk space per machine that can be served exclusively with HBase around 6T, unless you have a very read-heavy workload. In that case the Java heap should be 32GB (20G regions, 128M memstores, the rest defaults).

>   — Lars Hofhansl

>   http://hadoop-hbase.blogspot.com/2013/01/hbase-region-server-memory-sizing.html

##35. 根据列族数量
当前Hbase在处理2或3个以上列族时，表现不是很好，所以控制你schema中的列族数尽量少点。目前flush和compaction是在每个region的基础上进行。所以当一个列族操作大量数据时会引发flush，而相连的列族也会进行flush，即使它们操作的数据量很少。当许多列族存在flush和compaction相互作用时，会产生大量不必要的i/o（这个通过使flush和compaction只针对一个列族来解决）

尽量在你的schema中使用一个列族。只有数据访问固定在特定的列时，可以引入第二个和第三个列族.例如，你有两个列族,但你查询的时候总是访问其中的一个，从来不会两个一起访问。

###35.1. 列族的基数
当表中存在多个列在时，注意表的基数（行的数量）。如果ColumnfamliyA有100万行，而ColumnFamilyB有10亿行，CFA的数据可能分散在许多regions中（及RS中），这将导致CFA的scans操作非常低效。

##36. 行键设计
###36.1. Hotspotting
Hbase中行是按行键的字典序列排序的。这种设计优化scans操作，让你可以将相关的行存储在一起，或靠近的行将一起被读取。当然，row keys设计不好是hotspotting一个常见的原由。hotspotting发生在当大量客户流量流向一个节点或一些节点或一个集群时。这个流量可代表读、写或其他操作。它可能会淹没负责管理这个region的单台机器，导致其性能下降及导致region不可用。也可能会对同一region server管理的其他region产生不好的影响，如不能服务所需的负载。要想集群被充分使用，设计数据访问模式很重要。

避免写操作时的hotspotting，把row key设计成这样：行确实是需要在同一个region。但in the bigger picture，数据会被写倍集群中多个region，而不是一次一个。下面会描述一些常见的避免hotspotting技术，以及它们的优缺点。

_**Salting**_

这里的salting与加密无关，指的是在row key的开始中加入随机数据。这里，salting指的是给row key随机配置一个前缀，使它与原本排序不同。可能的前缀数量要与你想要散布数据的region个数相同。如果你有一些“hot”row key模式反复出现在其他更均匀行中，salting会有帮助的。思考下面的例子，Salting可以传播写入到多个负载，以及证明一些读的负面启示。

_**Example 16. Salting Example**_

>  假定你有以下行键表，你的表被分割成一个字母表中的字母一个区域，前缀‘a’是一个区域，‘b’是另一个。这个表中，同一个region中所有的行以f开头。这个例子关注下面这样的行键：

>      foo0001
>      foo0002
>      foo0003
>      foo0004

>   现在假定你你将这些分布在四个不同的区域，使用四个不同的salts：a，b，c，d。这个场景中，每个单词前缀都在不同区域上。在使用salts后，你有下面这样的行键。既然你可以写到四个分开的区域，理论上，当写入时，你有四倍的吞吐量比吸入同一region。

>      a-foo0003
>      b-foo0001
>      c-foo0004
>      d-foo0002

>    Then, if you add another row, it will randomly be assigned one of the four possible salt values and end up near one of the existing rows.

>      a-foo0003
>      b-foo0001
>      c-foo0003
>      c-foo0004
>      d-foo0002

>    既然这个分配是随机的，如果你想要获得字典序列的行，你要做更多工作。这样，salting增加来写入时的吞吐量，但读时会有消耗。

_**Hashing**_

不使用随机分配，你可以使用一个单向散列的方式，可以使已知行总是被同一前缀salted，这种方式是一种在RS上分散负载，而允许读取时可预测的方式。使用确定的hash，允许客户端重建完整的行键以及像平常一样使用Get操作获取完整的行。

_**Example 17. Hashing Example**_

>  Given the same situation in the salting example above, you could instead apply a one-way hash that would cause the row with key foo0003 to always, and predictably, receive the a prefix. Then, to retrieve that row, you would already know the key. You could also optimize things so that certain pairs of keys were always in the same region, for instance.

_**Reversing the Key**_

第三个常见的避免hotspotting的技巧是颠倒固定宽度或数量的行键，这样最频繁改变的部分是第一个。这有效地随机化行键，但牺牲了行排序属性。

###36.2 单调递增的行键/时间序列数据
在Tom White的Hadoop: The Definitive Guide一书中，有一个章节描述了一个值得注意的问题：在一个集群中，一个导入数据的进程一动不动，所有的client都在等待一个region(就是一个节点)，过了一会后，变成了下一个region...如果使用了单调递增或者时序的key就会造成这样的问题。详情可以参见IKai画的漫画monotonically increasing values are bad。使用了顺序的key会将本没有顺序的数据变得有顺序，把负载压在一台机器上。所以要尽量避免时间戳或者(e.g. 1, 2, 3)这样的key。

如果你确实需要上传时间序列数据到Hbase中，可以参考下OpenTSDB，这是个成功的例子。它有一页描述它在Hbase中使用的schema。OpenTSDB中使用了有效的[metric_type][event_timestamp]键格式，这个乍一看会与之前不要在键中使用时间戳的建议相悖。然而，这里的不同之处是没有把时间戳放在开头，这种设计的假设是会有许多不同的metric types，因此即使不断有metric type混合的输入数据流，Puts会被分散到表中各个region上。

###36.3. 试着最小化行列尺寸
HBase中，值总是承载着它们的坐标；当cell值在系统中传递时，它总是和它的列、行和时间戳一起。如果你的行和列的名字要是太大(甚至比value的大小还要大)的话，你可能会遇到一些有趣的情况。One such is the case described by Marc Limotte at the tail of HBASE-3551 (recommended!). Therein, the indices that are kept on HBase storefiles (StoreFile (HFile)) to facilitate random access may end up occupying large chunks of the HBase allotted RAM because the cell value coordinates are large. Mark in the above cited comment suggests upping the block size so entries in the store file index happen at a larger interval or modify the table schema so it makes for smaller rows and column names. Compression will also make for larger indices. See the thread a question storefileIndexSize up on the user mailing list.

大部分情况，小的低效没有那么重要。不幸的是，这里却会有影响。不管选择什么模式，列族、行键、属性都会在数据中 重复上亿次。

####36.3.1. 列族
列族名要尽可能小。最好用一个字母如用“d”表示data/default

See KeyValue for more information on HBase stores data internally to see why this is important.

####36.3.2. 属性
尽管繁琐的属性名（如myVeryImportantAttribute），更好理解，但存在HBase中最好短点（如 via）

See keyvalue for more information on HBase stores data internally to see why this is important.

####36.3.3. 行键长度
保持它们合理的短，即它们对被需要的数据获取依然是有用的(e.g., Get vs. Scan)。一个短键对数据访问无用不会比一个具有更好的get/scan性质的长键更好。设计行键需要权衡。

####36.3.4. 字节模式
一个long是8字节。可以在这8个字节中存储无符号型数据到18,446,744,073,709,551,615。如果你存储这些数据为字符串，假定一个字节一个字符，你需要大概3倍的字节数。

不信? 下面是示例代码，可以自己运行一下。

    //long
    //
    long l = 1234567890L;
    byte[] lb = Bytes.toBytes(l);
    System.out.println("long bytes length: " + lb.length);  //returns 8 
    
    String s = String.valueOf(l);
    byte[] sb = Bytes.toBytes(s);
    System.out.println("long as string length:" + sb.length); //returns 10
    
    //hash
    //
    MessageDigest md = MessageDigest.getInstance("MD5");
    byte[] digest = md.digets(Bytes.toBytes(s));
    System.out.println("md5 digest bytes length:" +digest.length); //returns 16
    
    String sDigest = new String(digest);
    byte[] sbDigest = Bytes.toBytes(sDigest);
    System.out.println("md5 digest as string length:" +sbdigest.length); //returns 26
    
不幸的是，使用二进制代表类型，将是你的数据在代码之外很难理解。例如，当你加入一个值时，你将在shell中看到如下情况：

    hbase（main):001:0> incr 't','r', 'f:q',1
    COUNTER VALUE = 1
    
    hbase(main):002:0> get 't', 'r'
    COLUMN                                        CELL
    f:q                                          timestamp=1369163040570,
    value=\x00\x00\x00\x00\x00\x00\x00\x01
    1 row(s) in 0.0310 seconds

shell尽力去打印字符串，这里它决定仅仅打印16进制。同样的情况将发生在你区域名字内的行键上。如果你了解存储的内容，那就没关系，但是如果任意数据都能被放入到同一cells中，那将变得不可读。这是主要要权衡的地方。

###36.4. Reverse Timestamps
>  Reverse Scan API<br>
>  HBASE-4811 implements an API to scan a table or a range within a table in reverse, reducing the need to optimize your schema for forward or reverse scanning. This feature is available in HBase 0.98 and later. See https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Scan.html#setReversed%28boolean for more information.

在数据库处理中一个常见问题是快速找到一个值的最近使用的版本。使用反时间戳作为键的一部分对这个问题很有效。Also found in the HBase chapter of Tom White’s book Hadoop: The Definitive Guide (O’Reilly), the technique involves appending (Long.MAX_VALUE - timestamp) to the end of any key, e.g. [key][reverse_timestamp].

表中最近的键值能够通过用【key】进行Scan操作找到并获取第一个记录。因为HBase已经排好序，该键排在任何比它老的行键的前面，所以必然是第一个。

这个技术可以用来替代Number of Versions，其目的是保存“永久”版本，或长时间保存，同时，使用同样的scan方法可以快速访问其他版本。

###36.5. 行键和列族
行键在列族范围内。因此，同样的行键可以存在于一个表的每个列族中，而不产生冲突。

###36.6. 行键不变性
行键不可以改变。它们唯一被改变的方法是删掉再重新插入。This is a fairly common question on the HBase dist-list so it pays to get the rowkeys right the first time (and/or before you’ve inserted a lot of data).

###36.7. 行键和区域分割的关系。
如果你提前分割你的表， 理解你的行键将怎样分布在区域范围上是很重要的。思考下使用可显示的16进制字符在键的开头（e.g."0000000000000000" to "ffffffffffffffff"）通过Bytes.split获得键的范围，使用了创建区域时的分割策略，10个区域将产生下面的分割
    
    48 48 48 48 48 48 48 48 48 48 48 48 48 48 48 48                                // 0
    54 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10 -10                 // 6
    61 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -67 -68                 // =
    68 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -124 -126  // D
    75 75 75 75 75 75 75 75 75 75 75 75 75 75 75 72                                // K
    82 18 18 18 18 18 18 18 18 18 18 18 18 18 18 14                                // R
    88 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -40 -44                 // X
    95 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -97 -102                // _
    102 102 102 102 102 102 102 102 102 102 102 102 102 102 102 102                // f
    
问题是从第二个区域开始所有数据将开始堆叠，最后一个区域将产生一个“lumpy”（或可能是“hot")区域问题。要理解为什么，参考下ASCII表。 0是字节”48“，f是字节“102”，但是在字节值（58-96）之间有很大的间隔，这可能永不会出现在键值空间中，因为唯一的值是从【0-9】和【a-f】。因此中间区域永远不会被使用。在对这个例子中的键空间进行预分割工作时，需要分割的自定义。

lesson #1： 预分割通常是一个最佳实践，但你需要预分割以所有区域在键空间中都是可访问的方式。这里例子说明了16进制键空间的问题，同样的问题能在任意键空间中发生。了解你的数据。

lesson #2： 通常不建议，使用16进制键依然对预分割表有作用，只要创建的区域在键空间中是可访问的。

下面是一个关于如何进行适当的分割对16进制键：

    public static boolean createTable(Admin admin, HTableDescriptor table, byte[][] splits)
    throws IOException {
      try {
        admin.createTable(table, splits);
        return true;
      } catch (TableExistException e) {
        logger.info("table"+table.getNameAsString() + "already exist");
        // the table already exists...
        return false;
      }
    } 
    
    public static byte[][] getHexSplits(String startKey, String endKey, int numRegions) {
      byte[][] splits = new byte[numRegions-1][];
      BigInteger lowestKey = new BigInteger(startKey, 16);
      BigInteger hightestKey = new BigInteger(endKey, 16);
      BigInteger range = highestKey.substract(lowestKey);
      BigInteger regionIncrement = range.divide(BigInteger.valueOf(numRegions));
      lowestKey = lowestKey.add(regionIncrement);
      for (int i = 0; i < numRegion - 1;i++) {
        BigInteger Key = lowestKey.add(regionIncrement.multiply(BigInteger.valueOf(i)));
        byte[] b = String.format("%016x", key).getBytes();
        splits[i]=b;
      }
      return splits;
    }

##37. 版本数
###37.1 最大版本数
通过HColumnDescriptor，可以配置每个列族存储的最大版本号。默认最大版本是1。这是一个重要参数原因已在前面数据模型中描述：HBase不会覆盖行值，但是会根据时间保存每行的不同值。多余的版本会在compaction阶段移除。根据应用需要，最大版本数需要增加或减少。

不建议将最大版本数设置到非常大（几百或者更多），除非旧值对你来说非常重要因为这将大大增加StoreFile的大小。

###37.2. 版本的最小值
就像行版本的最大值，通过HColumnDescriptors为每个列族配置要保存行版本的最小值。默认最小版本是0，意味着整个功能被禁用了。行版本最小值这个参数和参数time-to-live一起使用，和行版本数结合起来
