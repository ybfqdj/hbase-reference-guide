Apache HBase Configuration
本章将扩展快速开始一张，来进一步扩展HBase的配置。仔细阅读本章，特别是Basic Prerequisites来确保你HBase的测试和部署能够正常进行，并防止数据丢失。
3. Configuration Files
Apache HBase和Hadoop使用了同样的配置系统，所有的配置文件都在conf/目录，每个节点上要保持同步。

HBase Configuration File Descriptions

backup-masters
默认不存在，使用纯文本文件（plain-text），写入哪台主机要启动备份Master进程，一行一个主机

hadoop-metrics2-hbase.properties
用来连接HBase Hadoop’s Metrics2 framework。See the Hadoop Wiki entry for more information on Metrics2. Contains only commented-out examples by default.

hbase-env.cmd and hbase-env.sh
用来设定HBase工作环境的脚本，包含java位置、java选项和其他环境变量，文件包含许多注释（commented-out）例子。

hbase-policy.xml
默认给RPC服务器使用的文件配置，用来对客户端请求作出授权决定，只在HBase安全启用下使用。

hbase-site.xml
HBase主配置文件，这个文件指定配置选项可以覆盖HBase默认的配置。我们可以在docs/hbase-default.xml下看到默认配置文件，但不要修改它。你也能在Hbase Configuration tab of HBase Web UI查看集群的整个有效配置。

log4j.properties
Configuration file for HBase logging via log4j.

regionservers
纯文本文件：包含在集群中要运行RS的主机列表。默认情况下这个文件包含单个本地主机，它应该包含主机名或者ip地址，一行一个，如果集群中每个节点都将运行一个RS在启本地端，那文件应该仅仅包含本地主机


4. Basic Prerequisites
这小节列出需要的服务和一些需要的系统配置
In HBase 0.98.5 and newer, you must set JAVA_HOME on each node of your cluster. hbase-env.sh provides a handy mechanism to do this.
ssh、DNS、Loopback IP（127.0.0.1 =》 localhost）、NTP
Limits on Number of Files and Processes (ulimit)
HBase是一个数据库，需要有能够打开大量文件的能力。许多linux发布版本都限制来了单个用户最多只能打卡1024个文件
You can check this limit on your servers by running the command ulimit -n when logged in as the user which runs HBase. See the Troubleshooting section for some of the problems you may experience if the limit is too low. You may also notice errors such as the following:
2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Exception increateBlockOutputStream java.io.EOFException
2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6935524980745310745_1391901

建议将限制提升到至少10000,最好是10240.，因为值通常被表示为1024的倍数。每个ColumnFamily 至少有一个存储文件，可能超过6个存储文件如果区域欠载。The number of open files required depends upon the number of ColumnFamilies and the number of regions. 下面是一个计算
rs上打开文件可能值的公式：(StoreFiles per ColumnFamily) x (regions per RegionServer)
例如，假定图表每个region有三个CF，每个CF有3个storefiles，在RS上有100个region，所以JVM将打开900=3×3×100个文件描述符，不包含JAR files, configuration files, and others.打开一个文件不会占用太多资源，而允许一个用户打开太多文件的风险也是极小的。
另外一个限制是一个用户一次可以运行进程数，In Linux and Unix, the number of processes is set using the ulimit -u command.Under load, a ulimit -u that is too low can cause OutOfMemoryError exceptions. See Jack Levin’s major HDFS issues thread on the hbase-users mailing list, from 2011.
配置文件描述符和进程数的最大值对正在运行HBase进程的用户来说，这是一个操作系统配置而不是HBase配置。确保设置已经为运行HBase的用户做过修改也是很重要的。去HBase log看下是哪个用户启动来HBase以及用户的ulimit配置。 A useful read setting config on your hadoop cluster is Aaron Kimball’s Configuration Parameters: What can you just ignore?
4.1 Hadoop
4.1.6. dfs.datanode.max.transfer.threads
一个HDFS DN有一次能够serve的文件上界，读取文件前，确保你配置过Hadoop’s conf/hdfs-site.xml,setting the dfs.datanode.max.transfer.threads value to at least the following:

<property>
  <name>dfs.datanode.max.transfer.threads</name>
  <value>4096</value>
</property>

Be sure to restart your HDFS after making the above configuration.没有配置这个项会出现奇怪的失败
For example:

10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block
          blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No live nodes
          contain current block. Will get new block locations from namenode and retry...
          
  
  
4.2. ZooKeeper Requirements   
ZooKeeper 3.4.x is required as of HBase 1.0.0. HBase makes use of the multi functionality that is only available since 3.4.0 (The useMulti configuration option defaults to true in HBase 1.0.0). See HBASE-12241 (The crash of regionServer when taking deadserver’s replication queue breaks replication) and HBASE-6775 (Use ZK.multi when available for HBASE-6710 0.92/0.94 compatibility fix) for background.



5. HBase run modes: Standalone and Distributed
HBase有两种启动模式 Standalone and Distributed。out of the box（初始？）HBase以单机模式运行。无论你用哪种模式，你都要配置在HBase conf目录下的相关文件，至少，你要配置hbase-env.sh的java_home,在这个文件中设置Hbase环境变量如堆大小、
其他JVM选项、log文件位置等

5.1. Standalone HBase
默认模式，已在快速开始中描述过，这中模式Hbase不使用HDFS，而是用本地文件系统代替--运行所有HBase服务和一个本地ZK在同一个JVM中。ZK和一个已知的端口绑定在一起，这样客户端可以和HBase通信


5.2. Distributed
分布式模式可分为伪分布式和全分布式。伪分布式所有守护程序都运行在一个节点上，而全分布式守护程序分布在集群中的所有节点上。这种命名法（nomenclature）来自Hadoop
伪分布式可以在本地文件和HDFS上运行，而全分布式只能在HDFS上。See the Hadoop documentation for how to set up HDFS. A good walk-through for setting up HDFS on Hadoop 2 can be found at http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide.

5.2.1. Pseudo-distributed
A pseudo-distributed mode is simply a fully-distributed mode run on a single host. Use this configuration testing and prototyping on HBase. Do not use this configuration for production nor for evaluating HBase performance.

5.3. Fully-distributed
默认情况下HBase运行以standalone运行，standalone和pseudo-distributed可用来小规模测试，对生产环境分布式更合适In distributed mode, multiple instances of HBase daemons run on multiple servers in the cluster.
像伪分布式一样，你要设置hbase-cluster.distributed这个属性为true。hbase.rootdir要配置成可用 的HDFS文件系统。另外，集群中的节点要配置成 RegionServers, ZooKeeper QuorumPeers, and backup HMaster servers. 
分布式RegionServers
一般情况下，你的集群将包含多个RS、主备Master、ZK守护程序运行在不同服务器上，conf/regionservers 在master上的这个文件包含主机表，每个主机一行，所有表中的主机上的RS将随着master服务起停。
Example 7. Example Distributed HBase Cluster
这是一个包含基本元素（bare-bones）的分布式Hbase集群的配置文件 conf/hbase-site.xml 实际工作的集群可能包含更多自定义的配置参数。大多数HBase配置指令有默认值，通常使用这些默认值，除非被 hbase-site.xml覆盖。

Procedure: HDFS Client Configuration
1、注：如果你在你的Hadoop集群上改变HDFS客户端配置，例如HDFS客户端的配置指令（directives），不是服务端的配置，你必须使用如下的方法来启动HBase并应用这些配置改变。
  a、在hbase-env.sh中增加你的HADOOP_CONF_DIR到环境变量HBASE_CLASSPATH
  b、在 ${HBASE_HOME}/conf下复制或最好链接(symlinks)一个hdfs-site.xml,或
  c、仅仅一点HDFS客户端配置把它们加入hbase-site.xml
  如：属性dfs.replication，如果你洗哪个运行5个副本，HBase将以默认3来创建文件，除非你做上面的操作使配置对HBase可用
  
  
  6. Running and Confirming Your Installation
确保首先运行HDFS。 在HADOOP_HOME directory目录执行bin/start-hdfs.sh，同过put和get文件进行测试确保HDFS运行。HBase一般不使用MR或YARN daemons。这些不用被启动
如果你在管理你自己的ZK，启动它并确定它在运行，不然HBase会启动ZK作为其启动进程的一部分
bin/start-hbase.sh
现在我们应该又拉一个正在运行的HBase instance，日志可以在logs子目录下找到，检查它们特别是如果Hbase没有正常启动
HBase会拉起一个UI来列出关键属性。默认情况下部署在主节点端口16010上，RS在16020以及一个 informational HTTP server在16030
Prior to HBase 0.98 the master UI was deployed on port 60010, and the HBase RegionServers UI on port 60030.

To stop HBase after exiting the HBase shell enter
$ ./bin/stop-hbase.sh
关闭可能要花点时间，特别是如果你的集群由许多机器组成。如果在分布式系统上运行，一定要确保所有HBase关闭，才能结束Hadoop daemons


7. Default Configuration
7.1. hbase-site.xml and hbase-default.xml
就像在Hadoop中一样在hdfs-site.xml文件中加入特定的HDFS配置，对HBase来说在conf/hbase-site.xml文件中编辑特定的自定义配置For the list of configurable properties, see hbase default configurations below or view the raw hbase-default.xml source file in the HBase source code at src/main/resources.
不是所有的配置选项都会在hbase-default.xml中体现，那些很少有人会改的配置只在代码中，唯一的方法去改变这些配置的方法就是去阅读源代码
Currently, changes here will require a cluster restart for HBase to notice the change

7.2. HBase Default Configuration
hbase.tmp.dir
本地文件系统的临时目录，为这个设定指定一个比/tmp（the usual resolve for java.io.tmpdir, as the '/tmp' directory is cleared on machine restart.）更持久的位置
Default ${java.io.tmpdir}/hbase-${user.name}

hbase.rootdir
Description：The directory shared by region servers and into which HBase persists. （Rs共享的目录以及HBase存在的目录）URL要严格满足文件系统，例如指定hdfs://namenode.example.org:9000/hbase   这里的HDFS目录‘/hbase’，HDFS实例的NN运行在namenode.example.org on port 9000  By default, we write to whatever ${hbase.tmp.dir} is set too — usually /tmp — so change this configuration or else all data will be lost on machine restart.

hbase.fs.tmp.dir
Description：A staging directory （临时目录）in default file system (HDFS) for keeping temporary data.
Default
/user/${user.name}/hbase-staging

hbase.bulkload.staging.dir
Description：批量加载（bulk loading）的临时目录
Default
${hbase.fs.tmp.dir}

hbase.cluster.distributed
Description：集群运行模式，默认false

hbase.zookeeper.quorum
Description zk集合以逗号分割的服务器表（Comma separated list of servers in the ZooKeeper ensemble？）默认为standalone和伪分布式设置为本地主机。对一个分布式来说，要设置为完整的ZK集合服务器，如果hbase-env.sh 中HBASE_MANAGES_Z被设置，这个是哪个hbase将start/stop ZK随着集群start/stop的servers表。客户端将使用这个表中的集合成员，and put it together with the hbase.zookeeper.clientPort config. and pass it into zookeeper constructor as the connectString parameter.
Default
localhost

hbase.local.dir
在本地文件系统上的目录用于本地存储  Default   ${hbase.tmp.dir}/local/

hbase.master.port
HBase Master绑定的端口  Default 16000
hbase.master.info.port
The port for the HBase Master web UI. Set to -1 if you do not want a UI instance run.  
默认：16010

hbase.master.info.bindAddress   Description  The bind address for the HBase Master web UI  Default  0.0.0.0

hbase.master.logcleaner.plugins
#LogCleaner 定期清理.oldlogs目录下的log。它会从hbase.master.logcleaner.plugins配置里加载所有BaseLogCleanerDelegate。某个log可以被删除，只有所有delegate都同意。
逗号分割的BaseLogCleanerDelegate表，会被LogsCleaner service引用。这些WAL（预写日志） cleaner按顺序被引用，所以可以把先调用的放到前面。你也可以补充自己的BaseLogCleanerDelegate，只要加到HBase的classpath下，要写下合格的完整类名，Always add the above default log cleaners in the list.
Default    org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner

hbase.master.logcleaner.ttl
WAL可以在.oldlogdir中保存的最长时间，之后会被Master线程清除 默认：600000

hbase.master.hfilecleaner.plugins
A comma-separated list of BaseHFileCleanerDelegate invoked by the HFileCleaner service. These HFiles cleaners are called in order, so put the cleaner that prunes the most files in front. To implement your own BaseHFileCleanerDelegate, just put it in HBase’s classpath and add the fully qualified class name here. Always add the above default log cleaners in the list as they will be overwritten in hbase-site.xml.
#HFileCleaner  定期清理.archive目录下的HFile。它会从hbase.master.hfilecleaner.plugins配置里加载所有BaseHFileCleanerDelegate。
Default  org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner

hbase.master.infoserver.redirect
不管Master是否listen to web ui 端口，重定向请求到 Master and RegionServer的web ui server
默认 true

hbase.regionserver.port
RS绑定的端口号 默认16020
hbase.regionserver.info.port  
The port for the HBase RegionServer web UI Set to -1 if you do not want the RegionServer UI to run.
默认16030

hbase.regionserver.info.bindAddress
Description   The address for the HBase RegionServer web UI   Default    0.0.0.0

hbase.regionserver.info.port.auto
Master或RS是否搜索端口来绑定页面，打开自动端口搜索如果hbase.regionserver.info.port被占用。Useful for testing, turned off by default.

hbase.regionserver.handler.count
RegionServers受理的RPC Server实例数量，对Master来说是Master能够受理的handler数量
默认30

hbase.ipc.server.callqueue.handler.factor
呼叫队列数量决定因素，0代表只有一个队列用于所有handler共享，1代表每个handler有自己的队列
Default   0.1

hbase.ipc.server.callqueue.read.ratio
将呼叫队列分为读、写队列

